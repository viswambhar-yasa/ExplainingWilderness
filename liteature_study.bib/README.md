# Article References

## Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation

- **Authors**: Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, Wojciech Samek
- **Year**: 2015
- **Journal**: PLOS ONE
- **Volume**: 10
- **Number**: 7
- **Pages**: e0130140
- **DOI**: [10.1371/journal.pone.0130140](https://doi.org/10.1371/journal.pone.0130140)
- **URL**: [Read article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)
- **Abstract**: This work proposes a methodology to visualize the contributions of single pixels to predictions for kernel-based classifiers and multilayered neural networks. These pixel contributions are presented as heatmaps, aiding human experts in understanding classification decisions and focusing further analysis on regions of interest. Evaluation was done on various datasets and pre-trained models.
- **Keywords**: Algorithms, Coding mechanisms, Imaging techniques, Kernel functions, Neural networks, Neurons, Sensory perception, Vision
- **Language**: English

## Layer-wise Relevance Propagation

- **Title**: Layer-wise Relevance Propagation - 공돌이의 수학정리노트 (Angelo's Math Notes)
- **URL**: [Read article](https://angeloyeo.github.io/2019/08/17/Layerwise_Relevance_Propagation_en.html)


## Methods for Interpreting and Understanding Deep Neural Networks

- **Authors**: Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller
- **Year**: 2018
- **Journal**: Digital Signal Processing
- **Volume**: 73
- **Pages**: 1-15
- **DOI**: [10.1016/j.dsp.2017.10.011](https://doi.org/10.1016/j.dsp.2017.10.011)
- **URL**: [Read article](http://arxiv.org/abs/1706.07979)
- **Abstract**: This paper introduces techniques for interpreting and explaining predictions of deep neural networks. It covers interpretation techniques, theory, recommendations, and practical applications for making efficient use of these techniques on real data.
- **Keywords**: Computer Science - Machine Learning, Statistics - Machine Learning

## Concept Backpropagation: An Explainable AI Approach for Visualising Learned Concepts in Neural Network Models

- **Authors**: Patrik Hammersborg, Inga Strümke
- **Year**: 2023
- **Publisher**: arXiv
- **DOI**: [10.48550/arXiv.2307.12601](https://doi.org/10.48550/arXiv.2307.12601)
- **URL**: [Read article](http://arxiv.org/abs/2307.12601)
- **Abstract**: This work presents an extension to concept detection, called concept backpropagation, which allows analyzing how information representing a given concept is internalized in a neural network model. It visualizes detected concepts in the input space, showing the information the model relies on for representing these concepts across various input modalities.
- **Keywords**: Computer Science - Machine Learning

## Layer-Wise Relevance Propagation for Neural Networks with Local Renormalization Layers

- **Authors**: Alexander Binder, Grégoire Montavon, Sebastian Lapuschkin, Klaus-Robert Müller, Wojciech Samek
- **Year**: 2016
- **Conference**: Artificial Neural Networks and Machine Learning – ICANN 2016
- **Pages**: 63-71
- **DOI**: [10.1007/978-3-319-44781-0_8](https://doi.org/10.1007/978-3-319-44781-0_8)
- **Abstract**: This paper proposes an extension to layer-wise relevance propagation for neural networks with local renormalization layers, a common non-linearity in convolutional neural networks. It evaluates the method on datasets such as CIFAR-10, ImageNet, and MIT Places.
- **Keywords**: Neural networks, Image classification, Interpretability


## Acquisition of chess knowledge in AlphaZero

- **Authors**: Thomas McGrath, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Martin Wattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, Vladimir Kramnik
- **Year**: 2022
- **Journal**: Proceedings of the National Academy of Sciences
- **Volume**: 119
- **Number**: 47
- **Pages**: e2206625119
- **DOI**: [10.1073/pnas.2206625119](https://doi.org/10.1073/pnas.2206625119)
- **URL**: [Read article](https://www.pnas.org/doi/abs/10.1073/pnas.2206625119)
- **Abstract**: This analysis delves into AlphaZero's knowledge acquisition in chess. Despite training solely by self-play, AlphaZero learns concepts akin to those of human chess players. Linear probes and behavioral analysis are used to quantify and analyze these concepts within the network.

## From attribution maps to human-understandable explanations through Concept Relevance Propagation

- **Authors**: Reduan Achtibat, Maximilian Dreyer, Ilona Eisenbraun, Sebastian Bosse, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin
- **Year**: 2023
- **Journal**: Nat Mach Intell
- **Volume**: 5
- **Number**: 9
- **Pages**: 1006-1019
- **DOI**: [10.1038/s42256-023-00711-8](https://doi.org/10.1038/s42256-023-00711-8)
- **URL**: [Read article](https://www.nature.com/articles/s42256-023-00711-8)
- **Abstract**: This work introduces Concept Relevance Propagation (CRP), which combines local and global perspectives in explainable AI. CRP offers insights into individual predictions by addressing 'where' and 'what' questions, providing more human-interpretable explanations.

## Adaption of Layerwise Relevance Propagation for Audio Applications

- **Authors**: Roman Kiyan, Nils Poschadel, Stephan Preihs, Jurgen Peissig
- **Language**: English
- **Abstract**: Details about Layerwise Relevance Propagation adapted for audio applications.

## From "Where" to "What": Towards Human-Understandable Explanations through Concept Relevance Propagation

- **Authors**: Reduan Achtibat, Maximilian Dreyer, Ilona Eisenbraun, Sebastian Bosse, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin
- **Year**: 2022
- **Publisher**: arXiv
- **DOI**: [10.48550/arXiv.2206.03208](https://doi.org/10.48550/arXiv.2206.03208)
- **URL**: [Read article](http://arxiv.org/abs/2206.03208)
- **Abstract**: This work introduces Concept Relevance Propagation (CRP), aiming to provide comprehensive insights into deep learning models' representations and reasoning. CRP combines local and global explanations, allowing for 'where' and 'what' interpretations without constraints.

## Layer-Wise Relevance Propagation: An Overview

- **Authors**: Grégoire Montavon, Alexander Binder, Sebastian Lapuschkin, Wojciech Samek, Klaus-Robert Müller
- **Year**: 2019
- **Book Title**: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
- **DOI**: [10.1007/978-3-030-28954-6_10](https://doi.org/10.1007/978-3-030-28954-6_10)
- **Abstract**: This chapter provides an overview of Layer-Wise Relevance Propagation (LRP), a technique for explaining machine learning models by highlighting input features supporting predictions. It discusses implementation, theoretical justifications, propagation rules, and extensions beyond deep neural networks.


## Software for Dataset-wide XAI: From Local Explanations to Global Insights with Zennit, CoRelAy, and ViRelAy

- **Authors**: Christopher Anders, David Neumann, Wojciech Samek, Klaus-Robert Müller, Sebastian Lapuschkin
- **Year**: 2021
- **Abstract**: This book introduces three software packages - Zennit, CoRelAy, and ViRelAy - aimed at scientists to explore model reasoning using attribution approaches and beyond. Zennit implements LRP and related approaches in PyTorch, CoRelAy constructs quantitative analysis pipelines for dataset-wide analyses of explanations, and ViRelAy is a web-application to interactively explore data, attributions, and analysis results.
- **URL**: [Read article](https://www.researchgate.net/publication/352792272_Software_for_Dataset-wide_XAI_From_Local_Explanations_to_Global_Insights_with_Zennit_CoRelAy_and_ViRelAy)

## Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models

- **Authors**: Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin
- **Year**: 2023
- **Abstract**: This framework, Reveal to Revise (R2R), offers an eXplainable Artificial Intelligence (XAI) life cycle for identifying, mitigating, and (re-)evaluating spurious model behavior iteratively. It focuses on correcting biases in machine learning models by revealing model weaknesses, detecting responsible artifacts, revising model behavior, and (re-)evaluating model performance and remaining sensitivity towards artifacts.
- **URL**: [Read article](http://arxiv.org/abs/2303.12641)

## Exploring Wilderness Characteristics Using Explainable Machine Learning in Satellite Imagery

- **Authors**: Timo T. Stomberg, Taylor Stone, Johannes Leonhardt, Immanuel Weber, Ribana Roscher
- **Year**: 2022
- **Abstract**: This work applies explainable machine learning techniques to satellite images in Fennoscandia to identify and analyze wild and anthropogenic areas. Through sensitivity analysis with interpretable artificial neural networks, the study contributes to remote sensing and conservation efforts by understanding wilderness characteristics.
- **URL**: [Read article](http://arxiv.org/abs/2203.00379)


## Band Selection in Sentinel-2 Satellite for Agriculture Applications

- **Authors**: Tianxiang Zhang, Jinya Su, Cunjia Liu, Wen-Hua Chen, Hui Liu, Guohai Liu
- **Year**: 2017
- **Abstract**: This paper explores band selection in Sentinel-2A satellite imagery for agriculture applications. It compares methods using traditional indices, specific bands (Red, NIR, and SWIR), and full bands of on-board sensors, demonstrating improved classification performance by directly using selected bands compared to using indices.
- **URL**: [Read article](http://ieeexplore.ieee.org/document/8081990/)
  
## Sentinel 2 Bands and Combinations

- **Author**: GISGeography
- **Year**: 2019
- **Abstract**: This resource provides information on Sentinel-2 satellite's 13 bands, including details on pixel size and the types of bands available (red, green, blue, near infrared, and short infrared bands).
- **URL**: [Read article](https://gisgeography.com/sentinel-2-bands-combinations/)

## Forest Fragmentation in Fennoscandia: Linking Habitat Requirements of Wood-associated Threatened Species to Landscape and Habitat Changes

- **Authors**: Jari Kouki, Satu Löfman, Petri Martikainen, Seppo Rouvinen, Anneli Uotila
- **Year**: 2001
- **Abstract**: This article discusses forest fragmentation in Fennoscandia and its impact on wood-associated threatened species. It explores the ecological importance of fragmentation, historical landscape changes, and the habitat requirements of threatened species in fragmented forests.
- **URL**: [Read article](https://doi.org/10.1080/028275801300090564)

## Comparison of Convolutional Neural Network Architectures for Face Mask Detection

- **Authors**: Siti Nadia Yahya, Aizat Faiz Ramli, Muhammad Noor Nordin, Hafiz Basarudin, Mohd Azlan Abu
- **Year**: 2021
- **Abstract**: This paper compares various pre-trained CNN architectures for face mask detection using transfer learning. It evaluates the performance of AlexNet, GoogleNet, ResNet-18, ResNet-50, and ResNet-101 and determines the number of training images required for achieving specific performance metrics.
- **URL**: [Read article](http://thesai.org/Publications/ViewPaper?Volume=12&Issue=12&Code=IJACSA&SerialNo=83)

# Additional In-Proceedings References

## ImageNet Classification with Deep Convolutional Neural Networks

- **Authors**: Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton
- **Year**: 2012
- **Abstract**: This paper discusses the application of deep convolutional neural networks for ImageNet classification. It explores the usage of these networks for image classification tasks, showcasing their effectiveness in large-scale image recognition.
- **URL**: [Read paper](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)

## Explaining Therapy Predictions with Layer-Wise Relevance Propagation in Neural Networks

- **Authors**: Yinchong Yang, Volker Tresp, Marius Wunderle, Peter A. Fasching
- **Year**: 2018
- **Abstract**: This paper introduces the application of Layer-wise Relevance Propagation (LRP) to explain clinical therapy predictions made by deep neural networks. It evaluates the algorithm's ability to highlight relevant features for therapy decisions and validates these explanations with clinical experts.
- **URL**: [Read paper](https://ieeexplore.ieee.org/document/8419358/)


## Explainability for Neural Networks

- **Author**: Laura Rieger
- **Abstract**: This article explores the concept of explainability for neural networks. It likely discusses various techniques and methodologies to make neural networks more interpretable.
- **File**: [Download PDF](Rieger - Explainability for neural networks.pdf)

## Concept-Level Explainable AI

- **Authors**: Wojciech Samek, TU Berlin
- **Abstract**: This article discusses concept-level explainable artificial intelligence, likely exploring methods and approaches to achieve interpretable AI systems at a conceptual level.
- **File**: [Download PDF](Samek and Berlin - Concept-Level Explainable AI.pdf)

## From Attribution Maps to Human-Understandable Explanations through Concept Relevance Propagation

- **Authors**: Reduan Achtibat, Maximilian Dreyer, Ilona Eisenbraun, Sebastian Bosse, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin
- **Year**: 2023
- **Abstract**: This article introduces Concept Relevance Propagation (CRP) as an approach to combine local and global perspectives in explainable AI. It aims to provide insights into a model's representation and reasoning through concept atlases and quantitative investigations.
- **URL**: [Read article](https://www.nature.com/articles/s42256-023-00711-8)


## Finding the Right XAI Method - A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science

- **Authors**: Philine Bommer, Marlene Kretschmer, Anna Hedström, Dilyara Bareeva, Marina M.-C. Höhne
- **Year**: 2023
- **Abstract**: This work introduces an evaluation framework for explainable artificial intelligence (XAI) methods in the context of climate science. It assesses various explanation properties and compares multiple local XAI methods applied to predict decades based on annual-mean temperature maps.
- **URL**: [Read paper](http://arxiv.org/abs/2303.00652)

## Enhancing Achievement and Interest in Mathematics Learning through Math-Island

- **Authors**: Charles Y. C. Yeh, Hercy N. H. Cheng, Zhi-Hong Chen, Calvin C. Y. Liao, Tak-Wai Chan
- **Year**: 2019
- **Abstract**: This paper describes Math-Island, a game-based learning environment designed to enhance mathematics achievement and interest among elementary students. An experiment conducted over two years showed improved mathematics achievement, especially in calculation and word problems, alongside increased interest in mathematics.
- **URL**: [Read article](https://doi.org/10.1186/s41039-019-0100-9)


## AI Regulation in the European Union and Trade Law

- **Authors**: Kristina Irion
- **Year**: 2021
- **Abstract**: This paper explores the impact of AI on consumer behavior and consumer rights within the European Union. It discusses how AI applications influence consumer markets, emphasizing the need for technologies to operate in ways that respect fundamental consumer rights.
- **URL**: [Read paper](https://www.ssrn.com/abstract=3786567)

## Assessment of Forest Cover Changes using Multi-temporal Landsat Observation

- **Authors**: Elahe Moradi, Alireza Sharifi
- **Year**: 2023
- **Abstract**: This study analyzes changes in the Zagros Mountains forest-steppe from 1986 to 2019 using remote sensing techniques. It examines forest cover changes and their implications for biodiversity and soil erosion in the region.
- **URL**: [Read article](https://doi.org/10.1007/s10668-021-02097-2)

## Economic Development and Forest Cover: Evidence from Satellite Data

- **Authors**: Jesús Crespo Cuaresma, Olha Danylo, Steffen Fritz, Ian McCallum, Michael Obersteiner, Linda See, Brian Walsh
- **Year**: 2017
- **Abstract**: This research explores the relationship between economic development and deforestation differences across countries using satellite data. It indicates income per capita as a significant determinant of cross-border forest cover differences.
- **URL**: [Read article](https://doi.org/10.1038/srep40678)

## Explainable AI (XAI): A Systematic Meta-survey of Current Challenges and Future Opportunities

- **Authors**: Waddah Saeed, Christian Omlin
- **Year**: 2023
- **Abstract**: This meta-survey outlines challenges and future research directions in Explainable AI (XAI) across different phases of the machine learning life cycle. It aims to guide future exploration in the XAI area.
- **URL**: [Read article](https://www.sciencedirect.com/science/article/pii/S0950705123000230)

## Machine Learning: Algorithms, Real-World Applications and Research Directions

- **Authors**: Iqbal H. Sarker
- **Year**: 2021
- **Abstract**: This paper provides an overview of various machine learning algorithms and their applications in real-world domains such as cybersecurity, smart cities, healthcare, and more. It highlights challenges and research directions in the field.
- **URL**: [Read article](https://doi.org/10.1007/s42979-021-00592-x)

## Review of Deep Learning: Concepts, CNN Architectures, Challenges, Applications, Future Directions

- **Authors**: Laith Alzubaidi, Jinglan Zhang, Amjad J. Humaidi, Ayad Al-Dujaili, Ye Duan, Omran Al-Shamma, J. Santamaría, Mohammed A. Fadhel, Muthana Al-Amidie, Laith Farhan
- **Year**: 2021
- **Abstract**: This comprehensive review covers deep learning concepts, CNN architectures, challenges, and applications across various domains. It also discusses computational tools and their influence on deep learning.
- **URL**: [Read article](https://doi.org/10.1186/s40537-021-00444-8)

## Explaining Nonlinear Classification Decisions with Deep Taylor Decomposition

- **Authors**: Grégoire Montavon, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek, Klaus-Robert Müller
- **Year**: 2017
- **Abstract**: This paper introduces a methodology for interpreting multilayer neural networks by decomposing classification decisions into contributions from input elements. It focuses on image classification tasks and evaluates the proposed method on datasets like MNIST and ILSVRC.
- **URL**: [Read article](https://www.sciencedirect.com/science/article/pii/S0031320316303582)


## On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation

- **Authors**: Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, Wojciech Samek
- **Year**: 2015
- **Abstract**: This work introduces a methodology for visualizing the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. It aims to provide pixel-wise explanations for nonlinear classifiers and evaluate them on various datasets including PASCAL VOC 2009 images, synthetic image data, MNIST handwritten digits, and the ImageNet model.
- **URL**: [Read article](https://doi.org/10.1371/journal.pone.0130140)

## Evaluating Explainable Artificial Intelligence Methods for Multi-label Deep Learning Classification Tasks in Remote Sensing

- **Authors**: Ioannis Kakogeorgiou, Konstantinos Karantzalos
- **Year**: 2021
- **Abstract**: This article assesses ten Explainable AI (XAI) methods applied to deep learning models for multi-label classification tasks in remote sensing. It investigates the interpretability and reliability of these methods, providing insights into their performance and computational costs.
- **URL**: [Read article](https://doi.org/10.1016/j.jag.2021.102520)

## Sanity Checks for Saliency Maps

- **Authors**: Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, Been Kim
- **Year**: 2020
- **Abstract**: The paper introduces a methodology to evaluate the explanations provided by saliency methods. It highlights the necessity of robustness and reliability in saliency maps, emphasizing the inadequacy of certain methods for sensitive tasks involving data or model intricacies.
- **URL**: [Read paper](http://arxiv.org/abs/1810.03292)
